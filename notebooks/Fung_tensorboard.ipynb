{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d5162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2292517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:20:12.835941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-04 22:20:12.835974: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/fung/.pyenv/versions/3.8.12/envs/EFPO/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0d954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n",
      "2022-03-04 22:20:14.195916: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2022-03-04 22:20:14.195961: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-OQ3QMKM): /proc/driver/nvidia/version does not exist\n",
      "2022-03-04 22:20:14.196374: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-04 22:20:14.309576: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data), info = tfds.load(\n",
    "    \"imdb_reviews/subwords8k\",\n",
    "    split=(tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "encoder = info.features[\"text\"].encoder\n",
    "\n",
    "# Shuffle and pad the data.\n",
    "train_batches = train_data.shuffle(1000).padded_batch(\n",
    "    10, padded_shapes=((None,), ())\n",
    ")\n",
    "test_batches = test_data.shuffle(1000).padded_batch(\n",
    "    10, padded_shapes=((None,), ())\n",
    ")\n",
    "train_batch, train_labels = next(iter(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba4dc19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5259 - accuracy: 0.6822 - val_loss: 0.3728 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:20:19.962716: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create an embedding layer.\n",
    "embedding_dim = 16\n",
    "embedding = tf.keras.layers.Embedding(encoder.vocab_size, embedding_dim)\n",
    "# Configure the embedding layer as part of a keras model.\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        embedding, # The embedding layer should be the first layer in a model.\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile model.\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train model for one epoch.\n",
    "history = model.fit(\n",
    "    train_batches, epochs=1, validation_data=test_batches, validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6925280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 6404), started 0:00:44 ago. (Use '!kill 6404' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-718b98a00fb3eda1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-718b98a00fb3eda1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir='logs/imdb-example/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "  for subwords in encoder.subwords:\n",
    "    f.write(\"{}\\n\".format(subwords))\n",
    "  # Fill in the rest of the labels with \"unknown\".\n",
    "  for unknown in range(1, encoder.vocab_size - len(encoder.subwords)):\n",
    "    f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(model.layers[0].get_weights()[0][1:])\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)\n",
    "\n",
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir logs/imdb-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8c59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b9b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"trialdataFung02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67957324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 301)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dde68a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.090932</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.021491</td>\n",
       "      <td>-0.097215</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.142039</td>\n",
       "      <td>0.045104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007293</td>\n",
       "      <td>-0.105503</td>\n",
       "      <td>0.040222</td>\n",
       "      <td>-0.005296</td>\n",
       "      <td>-0.021423</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.035484</td>\n",
       "      <td>-0.015481</td>\n",
       "      <td>-0.091475</td>\n",
       "      <td>-0.003674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>-0.142388</td>\n",
       "      <td>-0.053261</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.017446</td>\n",
       "      <td>0.024857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>-0.115145</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.002742</td>\n",
       "      <td>-0.035765</td>\n",
       "      <td>-0.088677</td>\n",
       "      <td>-0.047915</td>\n",
       "      <td>-0.012275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.043575</td>\n",
       "      <td>-0.089596</td>\n",
       "      <td>-0.059855</td>\n",
       "      <td>-0.027599</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.123403</td>\n",
       "      <td>-0.018598</td>\n",
       "      <td>-0.081314</td>\n",
       "      <td>-0.057007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>-0.064594</td>\n",
       "      <td>-0.017959</td>\n",
       "      <td>-0.049705</td>\n",
       "      <td>-0.062980</td>\n",
       "      <td>0.104403</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>-0.015006</td>\n",
       "      <td>0.024766</td>\n",
       "      <td>-0.046359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.126782</td>\n",
       "      <td>-0.071671</td>\n",
       "      <td>-0.020207</td>\n",
       "      <td>0.106401</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.038288</td>\n",
       "      <td>0.028167</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>-0.026489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074442</td>\n",
       "      <td>-0.097198</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.039933</td>\n",
       "      <td>0.137622</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>-0.047279</td>\n",
       "      <td>-0.037677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.116386</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>-0.031809</td>\n",
       "      <td>0.111071</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.025424</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>-0.027655</td>\n",
       "      <td>-0.004751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069993</td>\n",
       "      <td>-0.110918</td>\n",
       "      <td>0.015859</td>\n",
       "      <td>0.029177</td>\n",
       "      <td>0.165497</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>-0.029496</td>\n",
       "      <td>-0.074084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -0.002882 -0.090932  0.027915 -0.021491 -0.097215  0.003197   \n",
       "1           1  0.060205 -0.142388 -0.053261  0.006739  0.002351  0.010120   \n",
       "2           2 -0.043575 -0.089596 -0.059855 -0.027599  0.054356  0.123403   \n",
       "3           3  0.126782 -0.071671 -0.020207  0.106401 -0.012710 -0.038288   \n",
       "4           4  0.116386 -0.029600 -0.031809  0.111071 -0.017531 -0.025424   \n",
       "\n",
       "          6         7         8  ...       290       291       292       293  \\\n",
       "0  0.044597  0.142039  0.045104  ... -0.007293 -0.105503  0.040222 -0.005296   \n",
       "1  0.004299  0.017446  0.024857  ...  0.010719 -0.115145  0.003793  0.047363   \n",
       "2 -0.018598 -0.081314 -0.057007  ...  0.019487 -0.064594 -0.017959 -0.049705   \n",
       "3  0.028167  0.005505 -0.026489  ...  0.074442 -0.097198  0.065517  0.039933   \n",
       "4  0.030436 -0.027655 -0.004751  ...  0.069993 -0.110918  0.015859  0.029177   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.021423 -0.135647 -0.035484 -0.015481 -0.091475 -0.003674  \n",
       "1 -0.020292 -0.002742 -0.035765 -0.088677 -0.047915 -0.012275  \n",
       "2 -0.062980  0.104403  0.035142 -0.015006  0.024766 -0.046359  \n",
       "3  0.137622  0.014308  0.017518  0.005966 -0.047279 -0.037677  \n",
       "4  0.165497  0.025816 -0.052511  0.000903 -0.029496 -0.074084  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee25798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 7545), started 0:00:09 ago. (Use '!kill 7545' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2d13070c706e7dd2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2d13070c706e7dd2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir='logs/test/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "  for subwords in encoder.subwords:\n",
    "    f.write(\"{}\\n\".format(subwords))\n",
    "  # Fill in the rest of the labels with \"unknown\".\n",
    "  for unknown in range(1, encoder.vocab_size - len(encoder.subwords)):\n",
    "    f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(df.values)\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)\n",
    "\n",
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir logs/test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
